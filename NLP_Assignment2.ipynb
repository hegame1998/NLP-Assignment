{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS1XrKinpsTWWhW3F2ayxj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hegame1998/NLP-Assignment/blob/main/NLP_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510986b6-261b-4976-ac1d-114117927e36",
        "id": "CMJScJqEhxw6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Source Summary Evaluation ===\n",
            "Original sentences: 60\n",
            "Summary sentences: 45\n",
            "Sample summary:\n",
            "Natural Language Processing (NLP) is a sub-field of artificial intelligence that focuses on the interaction between computers and humans through natural language.\n",
            "The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable.\n",
            "Most NLP techniques rely on machine learning to derive meaning from human languages.\n",
            "Applications of NLP include speech recognition, text summarization, machine translation, sentiment analysis, and more.\n",
            "The field of NLP combines computational linguistics with statistical, machine learning, and deep learning models.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "=== Style Summary Evaluation ===\n",
            "Original sentences: 6\n",
            "Summary sentences: 4\n",
            "Sample summary:\n",
            "In the beginning, language was simple.\n",
            "It served only to convey the most basic of messagesâ€”danger, food, shelter.\n",
            "As human societies grew more complex, so too did their methods of communication.\n",
            "Writing systems emerged, stories were told, philosophies debated.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# No need to download nltk resources\n",
        "# Basic implementation using naive sentence tokenizer\n",
        "\n",
        "# ------------------------\n",
        "# Data Collection\n",
        "# ------------------------\n",
        "import requests\n",
        "\n",
        "# Define the input texts (you can replace these with your own content)\n",
        "# Change these to your actual GitHub raw URLs\n",
        "# source_url = \"https://github.com/hegame1998/NLP-Assignment/blob/main/source_text.txt\"\n",
        "# style_url = \"https://github.com/hegame1998/NLP-Assignment/blob/main/style_text.txt\"\n",
        "\n",
        "# Replace with your actual raw GitHub URLs\n",
        "source_url = \"https://raw.githubusercontent.com/hegame1998/NLP-Assignment/main/source_text.txt\"\n",
        "style_url = \"https://raw.githubusercontent.com/hegame1998/NLP-Assignment/main/style_text.txt\"\n",
        "\n",
        "# Load text from GitHub\n",
        "source_text = requests.get(source_url).text\n",
        "style_text = requests.get(style_url).text\n",
        "\n",
        "# Save the input texts (optional for reference or reuse)\n",
        "with open(\"source_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(source_text)\n",
        "\n",
        "with open(\"style_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(style_text)\n",
        "\n",
        "# ------------------------\n",
        "# Preprocessing (no punkt)\n",
        "# ------------------------\n",
        "\n",
        "def naive_sentence_tokenize(text):\n",
        "    import re\n",
        "    # Split sentences on punctuation followed by a space and capital letter\n",
        "    return re.split(r'(?<=[.?!])\\s+(?=[A-Z])', text)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    sentences = naive_sentence_tokenize(text)\n",
        "    return [s.strip() for s in sentences if len(s.strip()) > 0]\n",
        "\n",
        "# ------------------------\n",
        "# Feature Extraction\n",
        "# ------------------------\n",
        "\n",
        "def compute_target_lengths(len1, len2, max_token=4000):\n",
        "    total = len1 + len2\n",
        "    proportion1 = len1 / total\n",
        "    proportion2 = len2 / total\n",
        "    return int(max_token * proportion1), int(max_token * proportion2)\n",
        "\n",
        "# ------------------------\n",
        "# Model Training (Summarization Logic)\n",
        "# ------------------------\n",
        "\n",
        "def hierarchical_summarize(sentences, target_len, slice_size=20):\n",
        "    summary = []\n",
        "    for i in range(0, len(sentences), slice_size):\n",
        "        chunk = sentences[i:i + slice_size]\n",
        "        chunk_summary = simple_extract_summary(chunk, target_len)\n",
        "        summary.extend(chunk_summary)\n",
        "        if len(summary) >= target_len:\n",
        "            break\n",
        "    return summary[:target_len]\n",
        "\n",
        "def simple_extract_summary(sentences, max_sentences):\n",
        "    # Simple extractive summarization: pick first N sentences\n",
        "    return sentences[:max_sentences]\n",
        "\n",
        "# ------------------------\n",
        "# Evaluation\n",
        "# ------------------------\n",
        "\n",
        "def evaluate_summary(original, summary, label):\n",
        "    print(f\"=== {label} Summary Evaluation ===\")\n",
        "    print(f\"Original sentences: {len(original)}\")\n",
        "    print(f\"Summary sentences: {len(summary)}\")\n",
        "    print(\"Sample summary:\")\n",
        "    print(\"\\n\".join(summary[:5]))\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# ------------------------\n",
        "# Main Function\n",
        "# ------------------------\n",
        "\n",
        "def main_pipeline(source_text, style_text):\n",
        "    # Preprocessing\n",
        "    source_sentences = preprocess_text(source_text)\n",
        "    style_sentences = preprocess_text(style_text)\n",
        "\n",
        "    # Proportional length calculation\n",
        "    source_target_len, style_target_len = compute_target_lengths(\n",
        "        len(source_sentences), len(style_sentences), max_token=50\n",
        "    )\n",
        "\n",
        "    # Hierarchical summarization\n",
        "    source_summary = hierarchical_summarize(source_sentences, source_target_len)\n",
        "    style_summary = hierarchical_summarize(style_sentences, style_target_len)\n",
        "\n",
        "    # Evaluation\n",
        "    evaluate_summary(source_sentences, source_summary, \"Source\")\n",
        "    evaluate_summary(style_sentences, style_summary, \"Style\")\n",
        "\n",
        "    return source_summary, style_summary\n",
        "\n",
        "# Run the full pipeline\n",
        "source_summary, style_summary = main_pipeline(source_text, style_text)\n"
      ]
    }
  ]
}