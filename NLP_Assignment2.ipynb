{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+0DpTwxOgC6qLS2YXpYFT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hegame1998/NLP-Assignment/blob/main/NLP_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection"
      ],
      "metadata": {
        "id": "xq8_Mm37rOre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I started by importing the **requests** library and then loaded my input texts directly from GitHub using their raw file URLs. These are:\n",
        "\n",
        "* **source_text.txt →** the document I want to summarize.\n",
        "\n",
        "* **style_text.txt →** the document that gives the style I want to follow.\n"
      ],
      "metadata": {
        "id": "kIsfWFBGrSfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Collection & Import Library\n",
        "import requests\n",
        "\n",
        "# Replace with actual raw GitHub URLs\n",
        "source_url = \"https://raw.githubusercontent.com/hegame1998/NLP-Assignment/main/source_text.txt\"\n",
        "style_url = \"https://raw.githubusercontent.com/hegame1998/NLP-Assignment/main/style_text.txt\"\n",
        "\n",
        "# Load text from GitHub\n",
        "source_text = requests.get(source_url).text\n",
        "style_text = requests.get(style_url).text"
      ],
      "metadata": {
        "id": "T_jfXSiEyYPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify and preserve these files locally in the Colab environment, I wrote them out again:"
      ],
      "metadata": {
        "id": "A89YWEDq3AoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the input texts (optional for reference or reuse)\n",
        "with open(\"source_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(source_text)\n",
        "\n",
        "with open(\"style_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(style_text)"
      ],
      "metadata": {
        "id": "CQOfZRKV2tdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This decouples data from code and makes my summarizer reusable for any new pair of texts."
      ],
      "metadata": {
        "id": "OAMouOvX2uLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing (without NLTK)"
      ],
      "metadata": {
        "id": "jCsp4tIgyyIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because I didn’t want to rely on external libraries like **nltk.punkt** (which may fail to download), I wrote a simple sentence tokenizer using regular expressions. It splits the text at punctuation marks followed by capital letters — a basic but effective approach."
      ],
      "metadata": {
        "id": "0seOaD7hy2d1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing (no punkt)\n",
        "def naive_sentence_tokenize(text):\n",
        "    import re\n",
        "    # Split sentences on punctuation followed by a space and capital letter\n",
        "    return re.split(r'(?<=[.?!])\\s+(?=[A-Z])', text)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    sentences = naive_sentence_tokenize(text)\n",
        "    return [s.strip() for s in sentences if len(s.strip()) > 0]"
      ],
      "metadata": {
        "id": "DlP6_yCey1lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* It splits on sentence-ending punctuation (e.g., ., ?, !) followed by a capital letter.\n",
        "\n",
        "* It filters out empty results.\n",
        "\n",
        "* It works without any external dependencies.\n",
        "\n",
        "This is simple but effective for clean, structured English paragraphs."
      ],
      "metadata": {
        "id": "4NR96ex53m-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "GUkFCtgpzUdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To manage summarization within a limited context window (e.g., 4000 tokens or fewer), I calculated the proportional space each text should get based on their lengths. This way, I ensured fairness in how much summary content each document contributes."
      ],
      "metadata": {
        "id": "e3nf3MwuzW5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_target_lengths(len1, len2, max_token=4000):\n",
        "    total = len1 + len2\n",
        "    proportion1 = len1 / total\n",
        "    proportion2 = len2 / total\n",
        "    return int(max_token * proportion1), int(max_token * proportion2)"
      ],
      "metadata": {
        "id": "aL8Z8rGtzZ7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for Example about of this part of code:<br>\n",
        "If the source text has 90 sentences and the style has 10, and max_token=100, then:\n",
        "\n",
        "* Source gets 90%\n",
        "\n",
        "* Style gets 10%\n",
        "\n",
        "This ensures **fair representation** in the final combined prompt."
      ],
      "metadata": {
        "id": "QLaLt_y94AfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training (Summarization Logic)"
      ],
      "metadata": {
        "id": "4abkQTh0zirr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I built a **hierarchical summarization pipeline**. First, I divided the documents into smaller chunks. Then, I extracted a few key sentences from each chunk. I kept summarizing in this way until I reached the desired summary length.\n",
        "\n",
        "My summarization method is extractive, so I simply picked the first N sentences from each chunk."
      ],
      "metadata": {
        "id": "TSwQMNd6znTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarization Logic\n",
        "def hierarchical_summarize(sentences, target_len, slice_size=20):\n",
        "    summary = []\n",
        "    for i in range(0, len(sentences), slice_size):\n",
        "        chunk = sentences[i:i + slice_size]\n",
        "        chunk_summary = simple_extract_summary(chunk, target_len)\n",
        "        summary.extend(chunk_summary)\n",
        "        if len(summary) >= target_len:\n",
        "            break\n",
        "    return summary[:target_len]\n",
        "\n",
        "def simple_extract_summary(sentences, max_sentences):\n",
        "    # Simple extractive summarization: pick first N sentences\n",
        "    return sentences[:max_sentences]"
      ],
      "metadata": {
        "id": "vqEyHJn-zq5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The process of this part of code:\n",
        "\n",
        "* Efficient and avoids token overflow.\n",
        "\n",
        "* Keeps contextually important leading sentences.\n",
        "\n",
        "* Modular: easy to replace with more advanced summarizers later."
      ],
      "metadata": {
        "id": "I6J4yBEf4zTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "WHagCFxOz7iH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate my summaries, I printed the number of sentences in both the original and the summarized versions. I also displayed a few lines from the generated summary so I could visually assess the quality."
      ],
      "metadata": {
        "id": "iBk_qKOpz9oH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "def evaluate_summary(original, summary, label):\n",
        "    print(f\"=== {label} Summary Evaluation ===\")\n",
        "    print(f\"Original sentences: {len(original)}\")\n",
        "    print(f\"Summary sentences: {len(summary)}\")\n",
        "    print(\"Sample summary:\")\n",
        "    print(\"\\n\".join(summary[:5]))\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "_DtdCM1Tz_NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gave me quick insight into how well the summary compressed the original content."
      ],
      "metadata": {
        "id": "HfCGQdoX5SD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Pipeline"
      ],
      "metadata": {
        "id": "7oo6eiCD0KME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I built a **main_pipeline()** function to:\n",
        "\n",
        "* Preprocess both texts\n",
        "\n",
        "* Compute proportional summary lengths\n",
        "\n",
        "* Perform hierarchical summarization\n",
        "\n",
        "* Run the evaluation"
      ],
      "metadata": {
        "id": "HsBlLNUK0LvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Function\n",
        "\n",
        "def main_pipeline(source_text, style_text):\n",
        "    # Preprocessing\n",
        "    source_sentences = preprocess_text(source_text)\n",
        "    style_sentences = preprocess_text(style_text)\n",
        "\n",
        "    # Proportional length calculation\n",
        "    source_target_len, style_target_len = compute_target_lengths(\n",
        "        len(source_sentences), len(style_sentences), max_token=50\n",
        "    )\n",
        "\n",
        "    # Hierarchical summarization\n",
        "    source_summary = hierarchical_summarize(source_sentences, source_target_len)\n",
        "    style_summary = hierarchical_summarize(style_sentences, style_target_len)\n",
        "\n",
        "    # Evaluation\n",
        "    evaluate_summary(source_sentences, source_summary, \"Source\")\n",
        "    evaluate_summary(style_sentences, style_summary, \"Style\")\n",
        "\n",
        "    return source_summary, style_summary\n",
        "\n",
        "# Run the full pipeline\n",
        "source_summary, style_summary = main_pipeline(source_text, style_text)"
      ],
      "metadata": {
        "id": "682nlAEF0N6x",
        "outputId": "6055802a-43f4-47dd-e827-1a0fd94a8413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Source Summary Evaluation ===\n",
            "Original sentences: 60\n",
            "Summary sentences: 45\n",
            "Sample summary:\n",
            "Natural Language Processing (NLP) is a sub-field of artificial intelligence that focuses on the interaction between computers and humans through natural language.\n",
            "The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable.\n",
            "Most NLP techniques rely on machine learning to derive meaning from human languages.\n",
            "Applications of NLP include speech recognition, text summarization, machine translation, sentiment analysis, and more.\n",
            "The field of NLP combines computational linguistics with statistical, machine learning, and deep learning models.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "=== Style Summary Evaluation ===\n",
            "Original sentences: 6\n",
            "Summary sentences: 4\n",
            "Sample summary:\n",
            "In the beginning, language was simple.\n",
            "It served only to convey the most basic of messages—danger, food, shelter.\n",
            "As human societies grew more complex, so too did their methods of communication.\n",
            "Writing systems emerged, stories were told, philosophies debated.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running my text summarization pipeline, I evaluate both the source and the style summaries. Here's how to interpret the output:"
      ],
      "metadata": {
        "id": "K2uFViAF7Idd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Source Summary Evaluation"
      ],
      "metadata": {
        "id": "NY0TmRYd7Uip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What the means of OutPut:** <br>\n",
        "My original ***source text*** had 60 sentences (likely technical and informative, such as a Wikipedia article on NLP). My summarizer reduced this to **45 sentences**, based on the proportion of source-to-style sentence count.\n",
        "\n",
        "I chose a maximum budget (**max_token=50** total sentences), so 90% of that was allocated to the source (45 sentences), because the source was much longer than the style text.<br> **Interpretation:**\n",
        "\n",
        "* These sentences are **clear, technical, and fact-heavy** — which is appropriate for summarizing a technical topic.\n",
        "\n",
        "* The summary captures **core definitions, objectives, method**s, and **applications** of NLP.\n",
        "\n",
        "* It retains **coherence** even though it’s extractive (i.e., no paraphrasing or abstraction)."
      ],
      "metadata": {
        "id": "jhSPzkqN7bna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Style Summary Evaluation"
      ],
      "metadata": {
        "id": "KSAoy2jy8tn2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What the means of OutPut:** <br>\n",
        "The ***style text*** was shorter — only 6 sentences long — and likely poetic or philosophical in tone. The summarizer extracted 4 of those sentences to preserve the core tone and content. <Br> **Interpretation:**\n",
        "\n",
        "This summary captures the **evolution of language** in a more **narrative and emotional** tone.\n",
        "\n",
        "It matches the **style** of the original text: reflective, abstract, and humanistic.\n",
        "\n",
        "Even though it’s extractive, it maintains the **voice** and **style** well."
      ],
      "metadata": {
        "id": "gkj0Ku-Q8wvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Result"
      ],
      "metadata": {
        "id": "aCmcUzfw5vhY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When I ran the summarizer on my two texts, the result was:\n",
        "\n",
        "* The source text was long and technical (about NLP). It was reduced to a shorter, digestible summary that still captured key facts.\n",
        "\n",
        "* The style text was philosophical and emotional. It got summarized while preserving its poetic tone.\n",
        "\n",
        "* Each summary was proportionally scaled.\n",
        "\n",
        "* The code ran without external dependencies like nltk, making it lightweight and portable."
      ],
      "metadata": {
        "id": "ysDbPXJJ5yGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br> My summarizer doesn't just cut down text — it preserves the **function** of each passage:\n",
        "\n",
        "* **Informative tone** for source text.\n",
        "\n",
        "* **Philosophical tone** for style text.\n",
        "\n",
        "By keeping summaries proportional, I ensure **balanced input** if I later use these summaries in prompts for a downstream LLM task (e.g., style transfer, paraphrasing)."
      ],
      "metadata": {
        "id": "yv0Z3CA6_Rmk"
      }
    }
  ]
}